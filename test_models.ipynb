{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f30629-77ed-42ee-be58-aa761e3cc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import AUROC\n",
    "from torchmetrics.classification import BinaryAveragePrecision\n",
    "\n",
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import pickle\n",
    "import time\n",
    "import glob\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchmdnet import datasets, attention_weights\n",
    "from torchmdnet.models.model import load_model\n",
    "from torchmdnet.utils import make_splits\n",
    "from torchmdnet.data import Subset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchmetrics.functional.classification import binary_average_precision\n",
    "from torch.nn.functional import mse_loss, l1_loss\n",
    "\n",
    "def rmse(pred, target):\n",
    "    return torch.sqrt(mse_loss(pred, target))\n",
    "\n",
    "def null_model(predicted, ground_truth, final_test=False):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import numpy as np\n",
    "    n_tasks = ground_truth.shape[1]\n",
    "    ground_truth_np = ground_truth.cpu().numpy()\n",
    "    predicted_np = predicted.cpu().numpy()\n",
    "    auc = []\n",
    "    auc_dict = {i: float for i in range(n_tasks)}\n",
    "    for i in range(n_tasks):\n",
    "        if np.any(ground_truth_np[:, i] == 0) and np.any(ground_truth_np[:, i] == 1):\n",
    "            auroc = AUROC(task='binary', ignore_index=-100)\n",
    "            auc.append(auroc(torch.zeros_like(ground_truth[:, i])+1., ground_truth[:, i]))\n",
    "            auc_dict[i] = auc\n",
    "        else:\n",
    "            continue\n",
    "    if final_test:\n",
    "        return auc_dict, sum(auc) / len(auc)\n",
    "\n",
    "    return sum(auc) / len(auc)\n",
    "\n",
    "\n",
    "def null_model_pr(predicted, ground_truth, final_test=False):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import numpy as np\n",
    "    n_tasks = ground_truth.shape[1]\n",
    "    ground_truth_np = ground_truth.cpu().numpy()\n",
    "    predicted_np = predicted.cpu().numpy()\n",
    "    auc = []\n",
    "    auc_dict = {i: float for i in range(n_tasks)}\n",
    "    for i in range(n_tasks):\n",
    "        if np.any(ground_truth_np[:, i] == 0) and np.any(ground_truth_np[:, i] == 1):\n",
    "            average_precision = BinaryAveragePrecision(threshold=None, ignore_index=-100)\n",
    "            auc.append(average_precision(torch.zeros_like(ground_truth[:, i]).float()+1., ground_truth[:, i]))\n",
    "            auc_dict[i] = auc\n",
    "        else:\n",
    "            continue\n",
    "    if final_test:\n",
    "        return auc_dict, sum(auc) / len(auc)\n",
    "\n",
    "    return sum(auc) / len(auc)\n",
    "\n",
    "def multitask_prauc(predicted, ground_truth, final_test=False):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import numpy as np\n",
    "    n_tasks = ground_truth.shape[1]\n",
    "    ground_truth_np = ground_truth.cpu().numpy()\n",
    "    predicted_np = predicted.cpu().numpy()\n",
    "    auc = []\n",
    "    auc_dict = {i: float for i in range(n_tasks)}\n",
    "    for i in range(n_tasks):\n",
    "        if np.any(ground_truth_np[:, i] == 0) and np.any(ground_truth_np[:, i] == 1):\n",
    "            average_precision = BinaryAveragePrecision(threshold=None, ignore_index=-100)\n",
    "            auc.append(average_precision(predicted[:, i], ground_truth[:, i]))\n",
    "            auc_dict[i] = auc\n",
    "        else:\n",
    "            continue\n",
    "    if final_test:\n",
    "        return auc_dict, sum(auc) / len(auc)\n",
    "\n",
    "    return sum(auc) / len(auc)\n",
    "\n",
    "def multitask_auc(predicted, ground_truth, final_test=False):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import numpy as np\n",
    "    n_tasks = ground_truth.shape[1]\n",
    "    ground_truth_np = ground_truth.cpu().numpy()\n",
    "    predicted_np = predicted.cpu().numpy()\n",
    "    auc = []\n",
    "    auc_dict = {i: float for i in range(n_tasks)}\n",
    "    for i in range(n_tasks):\n",
    "        if np.any(ground_truth_np[:, i] == 0) and np.any(ground_truth_np[:, i] == 1):\n",
    "            auroc = AUROC(task='binary', ignore_index=-100)\n",
    "            auc.append(auroc(predicted[:, i], ground_truth[:, i]))\n",
    "            auc_dict[i] = auc\n",
    "        else:\n",
    "            continue\n",
    "    #import pdb; pdb.set_trace()\n",
    "    if final_test:\n",
    "        return auc_dict, sum(auc) / len(auc)\n",
    "    return sum(auc) / len(auc)\n",
    "\n",
    "dataset_name = \"dili\"\n",
    "\n",
    "model_path = f\"./models/{dataset_name}.ckpt\"\n",
    "\n",
    "dataset = \"TDCTox\"\n",
    "dataset_arg = {\"num_conformers\": 1, \"conformer\": \"best\", \"dataset\": dataset_name}\n",
    "dataset_root = \"./data/TDCTox\"\n",
    "dataset_split = \"scaffold\"\n",
    "splits_path = f\"./data/TDCTox/splits/{dataset_name}_split_1_scaffold.npz\"\n",
    "\n",
    "#dataset = \"MoleculeNet\"\n",
    "#dataset_arg = {\"num_conformers\": 1, \"conformer\": \"best\", \"data_version\": \"geom\", \"dataset\": dataset_name}\n",
    "#dataset_root = \"./data/MoleculeNet\"\n",
    "#dataset_split = \"scaffold\"\n",
    "#splits_path = f\"./data/MoleculeNet/splits/{dataset_name}_seed1_confs1_scaffold.npz\"\n",
    "\n",
    "\n",
    "data = getattr(datasets, dataset)(dataset_root, **dataset_arg)\n",
    "\n",
    "splits = np.load(splits_path)\n",
    "data = DataLoader(torch.utils.data.Subset(data, splits[\"idx_test\"]), batch_size=1, num_workers=6)\n",
    "\n",
    "# load model\n",
    "print(\"loading model\")\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = load_model(model_path, device=device).eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe17d7-bc03-45f5-8f58-792fc1eafe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "preds_test = []\n",
    "targets_test = []\n",
    "energies = []\n",
    "\n",
    "\n",
    "for batch in tqdm(data):\n",
    "    labels.append(batch.tox_labels.numpy())\n",
    "    targets_test += batch.tox_labels.cpu()\n",
    "    energies.append(batch.y)\n",
    "    \n",
    "    z, pos, batch, Q = batch.z.to(device), batch.pos.to(device), batch.batch.to(device), batch.Q.to(device)\n",
    "    pred, deriv = model(z, pos, batch, Q=Q)\n",
    "    preds_test += pred.detach().cpu()\n",
    "    \n",
    "targets = torch.stack(targets_test)\n",
    "preds = torch.stack(preds_test)\n",
    "\n",
    "if dataset_name == \"ld50\":\n",
    "    print(f\"The MAE is {l1_loss(preds, targets)}\")\n",
    "    print(f\"The RMSE is {rmse(preds, targets)}\")\n",
    "    print(f\"The null-model RMSE is {rmse(torch.tensor([2.54]).repeat_interleave(len(targets)).unsqueeze(1), targets)}\")\n",
    "else:\n",
    "    aucs, mean_auc = multitask_auc(preds, targets.long(), final_test=True)\n",
    "    aucs_pr, mean_auc_pr = multitask_prauc(preds, targets.long(), final_test=True)\n",
    "    null_aucs, mean_null_aucs = null_model(preds, targets.long(), final_test=True)\n",
    "    null_aucs_pr, mean_null_aucs_pr = null_model_pr(preds, targets.long(), final_test=True)\n",
    "\n",
    "    print(f\"\\n The ROC-AUC is: {mean_auc}\\n\")\n",
    "    print(f\"\\n The PR-AUC is: {mean_auc_pr}\\n\")\n",
    "    print(f\"\\n The null model is: {mean_null_aucs}\\n\")\n",
    "    print(f\"\\n The PR null model is: {mean_null_aucs_pr}\\n\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
